---
title: 'Developing Data Products: Predict house price'
subtitle: 'Peer-graded Assignment - Course Project: Shiny Application and Reproducible Pitch'
author: 'Eddy âˆ†'
date: '09/03/2019'
# output: slidy_presentation
output: ioslides_presentation
---
<style>
pre {
  font-size: 15px;
}
</style>
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r require, include=FALSE}
setwd('~/projects/training/datascience/data_products/house')
required.packages <- c('doParallel', 'ggplot2', 'caret', 'MASS', 'forecast', 'GGally') # 'beepr', 'pgmm', 'knitr'
missing.packages <- setdiff(required.packages, rownames(installed.packages()))
if (length(missing.packages)) install.packages(missing.packages)
sapply(required.packages, require, character.only = TRUE)

if (length(setdiff(c('arrow'), rownames(installed.packages())))) devtools::install_github('apache/arrow/r')
library(arrow)

registerDoParallel(cores = detectCores() - 1)
getDoParWorkers()
# http://rpubs.com/ome9ax/475682
# https://omegax.shinyapps.io/house
# https://github.com/ome9ax/datascience/tree/master/data_products/house
```

## Project goal

This app is a simulator which predict [House Sales in King County, Washington State, USA](https://www.kaggle.com/harlfoxem/housesalesprediction) function of multiples criterias. The dataset can be retrieved from the [Kaggle](https://www.kaggle.com) platform.

This App is built as part as the coursera Developing Data Products course Peer-graded Assignment.

This **peer assessed assignment** has two parts.

- First, a Shiny application and deployed on Rstudio's servers.
- Second, and second the present reproducible pitch presentation about my application.

## Slide with Bullets

```{r load_data, cache = TRUE}
load_data <- function(file_url, data_dir = 'data', cache = FALSE){
  file_path <- file.path(data_dir, basename(file_url))
  as_tibble(transform(
    read.csv(file_path),
    # id = as.character(id),
    zipcode = factor(zipcode),
    date = as.integer(substring(as.character(date), 1, 8)),
    year = as.integer(substring(as.character(date), 1, 4)),
    month = as.integer(substring(as.character(date), 5, 6)),
    week = as.integer(format(as.Date(substring(as.character(date), 1, 8), format = '%Y%m%d'), '%W'))
  ))
}

raw_house <- load_data('kc_house_data.csv.xz', 'data')
names(raw_house)
```

The dataset contains `r nrow(raw_house)` rows and `r ncol(raw_house)` variables taken over a year.

Those data have been split in order to train a machine and perform predictions based on the user's inputs.

NOTE : Very slow on the 1st load due to the amount of data. 16000 lines need to be processed by the ML training.

## Average price per zipcode (data exploration)

The main panel and default tab is a **leaflet** interactive map, all the individuals transactions grouped by cluster function on the density displayed in the map. The value in the cluster in the count of the transactions.
<!-- Once broken down each cluster display the individual position of the transaction with the price in a popup once clicked. -->
The user can then freely explore the map to get a taste of the market in different places.
Both transactions and aggregates are filtered by the `Subset by price` slider.

The circles show the aggregated data per zipcode.

- the `lat` and `long` coordinate are the median value between the house positions for each `zipcode`.
- the `radius` of the circle is the count of houses
- the `colour` of the circle is the average **price** for the `zipcode` area.

## Prediction

The user can then enter the prediction tab where the predicted and validation dataset prices are displayed per zipcode.

The user get a price estimate based on the following predictors :

- the area `zipcode`
- overall `grade` given to the housing unit, based on King County grading system
- How good the `condition` is ( Overall )
- `sqft_lot` the square footage of the lot
- Number of `bedrooms` / House
- `week` number in the year

NOTE : brush the chart with your screen pointer to subset the displayed aggregates

# Annexes
## Prediction models
```{r model, echo = TRUE, cache = TRUE}
set.seed(99)

names(raw_house)[nearZeroVar(raw_house)]
house <- raw_house[, -nearZeroVar(raw_house)]

dataPartitions <- createDataPartition(y = house$price, p = 0.7, list = F)
training <- house[dataPartitions, ]
validation <- house[-dataPartitions, ]

trControl <- trainControl(method = 'repeatedcv', number = 8, repeats = 3, allowParallel = TRUE, verboseIter = FALSE)
modGbm <- train(price ~ zipcode + grade + condition + sqft_lot + bedrooms + week,
                data = training, method = 'gbm', trControl = trControl, verbose = F)
predGbm <- predict(modGbm, validation)
accGbm <- accuracy(predGbm, validation$price)
```

## Model details

```{r}
modGbm
```

## Price predictions

```{r price}
hist(validation$price, breaks = 90, freq = FALSE, col = 'darkgray', border = 'white'
     , xlab = 'Price', main = 'Price predictions')
lines(density(predGbm, adjust = 4), lty="dotted", col="darkgreen", lwd=2)
```

